---
title: "Project"
author: "hg8118"
date: "2023-05-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggExtra)
library(ggplot2)
library(car)
library(carData)
library(emmeans)
pacman::p_load(ROCR, pROC)
library(faraway)
library(MASS)
library(rpart.plot)
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(caret)
library(psych)
library(vip)
```

#importing the data from workspace

```{r, echo=FALSE,warning=FALSE,message=FALSE}
setwd("C:\\Users\\STSC\\Desktop\\stat 632\\Stat 632 Project")

```

```{r}
diabetes <- read.csv("diabetes.csv")
head(diabetes)
```

```{r}
pairs(Outcome ~., data = diabetes)
```

```{r}
cor_data <- diabetes[,1:8]
corPlot(cor_data, cex = 1.2)
```

```{r}
library(corrplot)
corrplot(cor(cor_data), method = "number",
         title = "method = 'number'",
         tl.pos = "n", mar = c(2, 1, 3, 1))
```

```{r}
model_1 <- glm(Outcome ~ ., data = diabetes, family = "binomial")
summary(model_1)
```

```{r}
round(vif(model_1),2)

```

Checking the corelations using VIF values \> 10 are highly corellated

```{r}
model_2 <- step(model_1) 
model_2

```

Based on above AIC model We can see that the best model suggested by AIC is

Outcome \~ Pregnancies + Glucose + BloodPressure + Insulin + BMI + DiabetesPedigreeFunction + Age

But as Insulin and Age appear to be is highly insignificant, so we try to convert them to factors to overcome this. and also by seeing the data we can see that Insulin has many Outliers with large values that do not exist practically. So we remove it from the model to get a better an dsignificant model.

```{r}
fit_1 <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure + BMI + 
    DiabetesPedigreeFunction + Age, data = diabetes, family = "binomial")
summary(fit_1)
vif(fit_1)
```

From above VIF values we can see that Pregnancies , Age are corelated and BMI and Glucose levels are Corelated .

Down here we are converting Age into 3 groups Young Age, Middle_Age, and Old_AGE as the age tends to be nearly significant from above statistics.

```{r}
diabetes$Outcome <- as.factor(diabetes$Outcome)
# Create a new column to hold the factor values
#0-1(0-18 years teen age and below), 19-40(Young Age), 41-60(middle age), 60-85(Old #Age)
diabetes$Age <- cut(diabetes$Age, 
                          breaks=c(0,18, 40, 60, 85), 
                          labels=c("0","1","2","3"), 
                          include.lowest=TRUE)

head(diabetes)
```

```{r}
new_dataset <- diabetes
head(new_dataset)
```

From above we have removed the Age from the dataset and created new dataset with age as factor

```{r}

```

```{r}
fit_2 <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure + BMI + 
    DiabetesPedigreeFunction + Age, data = diabetes, family = "binomial")
summary(fit_2)
```

```{r}
pairs(Outcome ~ Pregnancies + Glucose + BloodPressure+ BMI + DiabetesPedigreeFunction + Age,
                data = diabetes)
```

**Now We run the train test split** for the data to see how the model performs for the data

```{r}
set.seed(123)

# Create train-test split with 70-30 ratio
train_index <- createDataPartition(diabetes$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes[train_index, ]
test_data <- diabetes[-train_index, ]

# Fit logistic regression model on training data
T_T_S_model <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure+
                       BMI + DiabetesPedigreeFunction + Age, 
                     data = train_data, family = binomial)
# Predict on training data 
predictions <- predict(T_T_S_model, newdata = train_data, type = "response")
predicted_classes_train <- ifelse(predictions > 0.5, 1, 0)

# Predict on test data
predictions <- predict(T_T_S_model, newdata = test_data, type = "response")
predicted_classes_test <- ifelse(predictions > 0.5, 1, 0)

# Create confusion matrix for bot training data and testing data 
confusion_matrix_train <- table(train_data$Outcome, predicted_classes_train)
confusion_matrix<- table(test_data$Outcome, predicted_classes_test)
confusion_matrix_train
confusion_matrix

```

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
```

```{r}
# Calculate true positives, true negatives, false positives, false negatives
tp <- confusion_matrix[2, 2]
tn <- confusion_matrix[1, 1]
fp <- confusion_matrix[1, 2]
fn <- confusion_matrix[2, 1]

# Calculate sensitivity and specificity
sensitivity <- tp / (tp + fn)
specificity <- tn / (tn + fp)

# Print results
cat("Sensitivity:", sensitivity, "\n")
cat("Specificity:", specificity, "\n")

```

```{r}
# Load necessary packages
library(pROC)

# Predict probabilities on test data
predictions <- predict(T_T_S_model, newdata = test_data, type = "response")

# Create ROC curve object
roc_obj <- roc(test_data$Outcome, predictions)

# Plot ROC curve
plot(roc_obj, print.auc = TRUE, main = "ROC Curve for Diabetes Prediction")
```

We use **VIP** function to create a graph showing the importance of all variables

```{r}
vip(model_1, num_features = 8)

```
